import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt

# Define the latent dimension
latent_dim = 2  # Dimension of the latent space

# Define encoder
inputs = keras.Input(shape=(28, 28, 1))
x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)
x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation='relu')(x)
z_mean = layers.Dense(latent_dim, name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)

def sampling(args):
    z_mean, z_log_var = args
    batch = tf.shape(z_mean)[0]
    dim = tf.shape(z_mean)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon

z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])

encoder = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')

# Define decoder
latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(7 * 7 * 64, activation='relu')(latent_inputs)
x = layers.Reshape((7, 7, 64))(x)
x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)
x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)
out_decoder = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)

decoder = keras.Model(latent_inputs, out_decoder, name='decoder')

# Define VAE model
outputs = decoder(z)
vae = keras.Model(inputs, outputs, name='vae')

# Define loss function
reconstruction_loss = keras.losses.MeanSquaredError()(inputs, outputs)
kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
total_loss = reconstruction_loss + kl_loss
vae.add_loss(total_loss)
vae.compile(optimizer='adam')

# Load dataset (Replace this with your dataset)
(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()
x_train = np.expand_dims(x_train, -1).astype('float32') / 255.0
x_test = np.expand_dims(x_test, -1).astype('float32') / 255.0

# Train the VAE
vae.fit(x_train, epochs=10, batch_size=128, validation_data=(x_test, x_test))

# Visualize the latent space
def plot_latent_space(encoder, num_samples=5000):
    z_mean, _, _ = encoder.predict(x_test[:num_samples])
    plt.figure(figsize=(8, 6))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], alpha=0.5)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.title("Latent Space Visualization")
    plt.show()

plot_latent_space(encoder)
