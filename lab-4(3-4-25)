#restricted boltzman machine
import numpy as np
from scipy.ndimage import convolve

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import minmax_scale


def nudge_dataset(X, Y):
    """
    This produces a dataset 5 times bigger than the original one,
    by moving the 8x8 images in X around by 1px to left, right, down, up
    """
    direction_vectors = [
        [[0, 1, 0], [0, 0, 0], [0, 0, 0]],
        [[0, 0, 0], [1, 0, 0], [0, 0, 0]],
        [[0, 0, 0], [0, 0, 1], [0, 0, 0]],
        [[0, 0, 0], [0, 0, 0], [0, 1, 0]],
    ]

    def shift(x, w):
        return convolve(x.reshape((8, 8)), mode="constant", weights=w).ravel()

    X = np.concatenate(
        [X] + [np.apply_along_axis(shift, 1, X, vector) for vector in direction_vectors]
    )
    Y = np.concatenate([Y for _ in range(5)], axis=0)
    return X, Y


X, y = datasets.load_digits(return_X_y=True)
X = np.asarray(X, "float32")
X, Y = nudge_dataset(X, y)
X = minmax_scale(X, feature_range=(0, 1))  # 0-1 scaling

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

from sklearn import linear_model
from sklearn.neural_network import BernoulliRBM
from sklearn.pipeline import Pipeline

logistic = linear_model.LogisticRegression(solver="newton-cg", tol=1)
rbm = BernoulliRBM(random_state=0, verbose=True)

rbm_features_classifier = Pipeline(steps=[("rbm", rbm), ("logistic", logistic)])

from sklearn.base import clone

# Hyper-parameters. These were set by cross-validation,
# using a GridSearchCV. Here we are not performing cross-validation to
# save time.
rbm.learning_rate = 0.06
rbm.n_iter = 10

# More components tend to give better prediction performance, but larger
# fitting time
rbm.n_components = 100
logistic.C = 6000

# Training RBM-Logistic Pipeline
rbm_features_classifier.fit(X_train, Y_train)

# Training the Logistic regression classifier directly on the pixel
raw_pixel_classifier = clone(logistic)
raw_pixel_classifier.C = 100.0
raw_pixel_classifier.fit(X_train, Y_train)

from sklearn import metrics

Y_pred = rbm_features_classifier.predict(X_test)
print(
    "Logistic regression using RBM features:\n%s\n"
    % (metrics.classification_report(Y_test, Y_pred))
)

Y_pred = raw_pixel_classifier.predict(X_test)
print(
    "Logistic regression using raw pixel features:\n%s\n"
    % (metrics.classification_report(Y_test, Y_pred))
)

import matplotlib.pyplot as plt

plt.figure(figsize=(4.2, 4))
for i, comp in enumerate(rbm.components_):
    plt.subplot(10, 10, i + 1)
    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r, interpolation="nearest")
    plt.xticks(())
    plt.yticks(())
plt.suptitle("100 components extracted by RBM", fontsize=16)
plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)

plt.show()

#stack in rbm
#Stacks using RBM
import numpy as np
from sklearn.preprocessing import binarize

class Stack:
    def __init__(self, capacity):
        self.capacity = capacity
        self.stack = []

    def push(self, item):
        if len(self.stack) < self.capacity:
            self.stack.append(item)
            return True
        return False

    def pop(self):
        if not self.is_empty():
            return self.stack.pop()
        return None

    def is_empty(self):
        return len(self.stack) == 0

class RBM:
    def __init__(self, n_visible, n_hidden, learning_rate=0.1):
        self.n_visible = n_visible
        self.n_hidden = n_hidden
        self.lr = learning_rate

        self.weights = np.random.normal(0, 0.1, (n_visible, n_hidden))
        self.v_bias = np.zeros(n_visible)
        self.h_bias = np.zeros(n_hidden)

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def sample_hidden(self, visible):
        if visible.ndim == 1:
            visible = visible.reshape(1, -1)
        activation = np.dot(visible, self.weights) + self.h_bias
        prob_h = self.sigmoid(activation)
        sampled_h = binarize(prob_h, threshold=0.5)
        return prob_h, sampled_h

    def sample_visible(self, hidden):
        if hidden.ndim == 1:
            hidden = hidden.reshape(1, -1)
        activation = np.dot(hidden, self.weights.T) + self.v_bias
        prob_v = self.sigmoid(activation)
        sampled_v = binarize(prob_v, threshold=0.5)
        return prob_v, sampled_v

    def train(self, data, epochs=100, batch_size=10):
        n_samples = data.shape[0]

        for epoch in range(epochs):
            idx = np.random.permutation(n_samples)
            data_shuffled = data[idx]

            for i in range(0, n_samples, batch_size):
                batch = data_shuffled[i:i+batch_size]

                pos_hidden_probs, pos_hidden = self.sample_hidden(batch)
                pos_associations = np.dot(batch.T, pos_hidden_probs)

                neg_visible_probs, neg_visible = self.sample_visible(pos_hidden)
                neg_hidden_probs, neg_hidden = self.sample_hidden(neg_visible)
                neg_associations = np.dot(neg_visible.T, neg_hidden_probs)

                self.weights += self.lr * (pos_associations - neg_associations) / batch_size
                self.v_bias += self.lr * np.mean(batch - neg_visible, axis=0)
                self.h_bias += self.lr * np.mean(pos_hidden_probs - neg_hidden_probs, axis=0)

class StackRBM:
    def __init__(self, capacity, n_visible, n_hidden):
        self.stack = Stack(capacity)
        self.rbm = RBM(n_visible, n_hidden)

    def push_and_train(self, data):
        if self.stack.push(data):
            data_array = np.array(data).reshape(1, -1)
            self.rbm.train(data_array)
            return True
        return False

    def pop_and_reconstruct(self):
        data = self.stack.pop()
        if data is not None:
            data_array = np.array(data).reshape(1, -1)
            hidden_probs, hidden = self.rbm.sample_hidden(data_array)
            visible_probs, reconstructed = self.rbm.sample_visible(hidden)
            return reconstructed[0]
        return None

    def get_stack_size(self):
        return len(self.stack.stack)

if __name__ == "__main__":
    stack_rbm = StackRBM(capacity=5, n_visible=4, n_hidden=2)
    sample_data = [[1, 0, 1, 0], [0, 1, 0, 1], [1, 1, 0, 0], [0, 0, 1, 1]]
    for data in sample_data:
        success = stack_rbm.push_and_train(data)
        print(f"Pushed data {data}: {success}")
    reconstructed = stack_rbm.pop_and_reconstruct()
    if reconstructed is not None:
        print(f"Reconstructed data: {reconstructed}")
    print(f"Current stack size: {stack_rbm.get_stack_size()}")
